{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Copyright **`(c)`** 2024 Giovanni Squillero `<giovanni.squillero@polito.it>`  \n",
    "[`https://github.com/squillero/computational-intelligence`](https://github.com/squillero/computational-intelligence)  \n",
    "Free under certain conditions — see the [`license`](https://github.com/squillero/computational-intelligence/blob/master/LICENSE.md) for details.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from random import choice\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUZZLE_DIM = 5\n",
    "action = namedtuple('Action', ['pos1', 'pos2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This algorithm solves the puzzle problem using the A* algorithm with a priority queue. \n",
    "The goal is to find the shortest path (in terms of moves) to get the puzzle from an initial state to a goal state [1,2, ..., n-1, 0].\n",
    "\n",
    "available_actions() returns a list of valid moves that can be performed from the current position of the empty square;\n",
    "\n",
    "do_action() makes a move on the current state of the puzzle, returning a new state;\n",
    "\n",
    "goal_positions precalculates the target positions for each value in the puzzle, to speed up the calculation of heuristics using the divmod() function;\n",
    "\n",
    "heuristic() computes a heuristic value to estimate the remaining cost to reach the goal state via the parameters Manhattan distance and number of misplaced tiles;\n",
    "\n",
    "solve_puzzle() solves the puzzle using the A* algorithm;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def available_actions(state: np.ndarray) -> list['Action']:\n",
    "    x, y = [int(_[0]) for _ in np.where(state == 0)]\n",
    "    actions = list()\n",
    "    if x > 0:\n",
    "        actions.append(action((x, y), (x - 1, y)))\n",
    "    if x < PUZZLE_DIM - 1:\n",
    "        actions.append(action((x, y), (x + 1, y)))\n",
    "    if y > 0:\n",
    "        actions.append(action((x, y), (x, y - 1)))\n",
    "    if y < PUZZLE_DIM - 1:\n",
    "        actions.append(action((x, y), (x, y + 1)))\n",
    "    return actions\n",
    "\n",
    "def do_action(state: np.ndarray, action: 'Action') -> np.ndarray:\n",
    "    new_state = state.copy()\n",
    "    new_state[action.pos1], new_state[action.pos2] = new_state[action.pos2], new_state[action.pos1]\n",
    "    return new_state\n",
    "\n",
    "goal_positions = {value: divmod(value - 1, PUZZLE_DIM) for value in range(1, PUZZLE_DIM**2)}\n",
    "\n",
    "def heuristic(state: np.ndarray, goal: np.ndarray) -> int:\n",
    "    \"\"\" Optimizing heuristics based on Manhattan distance and the number of misplaced tiles. \"\"\"\n",
    "    manhattan_distance = 0\n",
    "    misplacement_count = 0\n",
    "    for x in range(PUZZLE_DIM):\n",
    "        for y in range(PUZZLE_DIM):\n",
    "            value = state[x, y]\n",
    "            if value != 0: \n",
    "                goal_x, goal_y = divmod(value - 1, PUZZLE_DIM)\n",
    "                manhattan_distance += abs(x - goal_x) + abs(y - goal_y)\n",
    "                if goal[x, y] != value:\n",
    "                    misplacement_count += 1\n",
    "    \n",
    "    return manhattan_distance + 2 * misplacement_count  \n",
    "\n",
    "def solve_puzzle(start_state: np.ndarray, goal_state: np.ndarray):\n",
    "    \"\"\"Solve puzzle n²-1 using the A* algorithm with an optimized priority queue.\"\"\"\n",
    "    frontier = []\n",
    "    heapq.heappush(frontier, (0, start_state.tolist(), [start_state.tolist()], 0))\n",
    "    visited = set()\n",
    "\n",
    "    while frontier:\n",
    "\n",
    "        f_cost, current_state, path, g_cost = heapq.heappop(frontier)\n",
    "        current_state = np.array(current_state)\n",
    "\n",
    "        if np.array_equal(current_state, goal_state):\n",
    "            return path\n",
    "\n",
    "        state_str = current_state.tobytes()\n",
    "        if state_str in visited:\n",
    "            continue\n",
    "        visited.add(state_str)\n",
    "\n",
    "        for act in available_actions(current_state):\n",
    "            new_state = do_action(current_state, act)\n",
    "            new_g_cost = g_cost + 1\n",
    "            new_f_cost = new_g_cost + heuristic(new_state, goal_state)\n",
    "            new_path = path + [new_state.tolist()]\n",
    "            heapq.heappush(frontier, (new_f_cost, new_state.tolist(), new_path, new_g_cost))\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure that the initial puzzle can be traced back to the final form of the problem (is solvable), the final solution to the problem is messed up by choosing a number of random moves, dictated by the RANDOMIZE_STEPS parameter.\n",
    "The number of RANDOMIZED_STEPS indicated is 150 and allows you to have a starting solution with a good level of randomization especially with PUZZLE_DIM <= 8, for larger dimensions it is inevitably necessary to increase the number of RANDOMIZED_STEPS, to the detriment of performance in terms of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOMIZE_STEPS = 150\n",
    "\n",
    "if PUZZLE_DIM == 0:\n",
    "    print(\"Solution found in 0 moves!\")\n",
    "    print(\"Step 0:\")\n",
    "    print([])\n",
    "elif PUZZLE_DIM == 1:\n",
    "    state = np.array([i for i in range(1, PUZZLE_DIM**2)] + [0]).reshape((PUZZLE_DIM, PUZZLE_DIM))\n",
    "    print(\"Solution found in 0 moves!\")\n",
    "    print(\"Step 0:\")\n",
    "    print(state)\n",
    "else:\n",
    "    state = np.array([i for i in range(1, PUZZLE_DIM**2)] + [0]).reshape((PUZZLE_DIM, PUZZLE_DIM))\n",
    "    for _ in tqdm(range(RANDOMIZE_STEPS), desc='Randomizing'):\n",
    "\n",
    "        state = do_action(state, choice(available_actions(state)))\n",
    "\n",
    "    goal_state = np.array([i for i in range(1, PUZZLE_DIM**2)] + [0]).reshape((PUZZLE_DIM, PUZZLE_DIM))\n",
    "\n",
    "    \n",
    "    solution = solve_puzzle(state, goal_state)\n",
    "\n",
    "    if solution:\n",
    "        print(f\"Solution found in {len(solution) - 1} moves!\")  \n",
    "        for step, s in enumerate(solution):\n",
    "            print(f\"Step {step}:\")\n",
    "            print(np.array(s))  \n",
    "    else:\n",
    "        print(\"No solution found.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CI2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
